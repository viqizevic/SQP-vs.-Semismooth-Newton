\chapter{Einführung}

Die nichtlineare Optimierung ist ein bedeutendes Gebiet der Mathematik.
Sie findet immer wieder Anwendungen in den schwierigen Problemen der Technik und
der Wirtschaft. Es wurden viele Verfahren entwickelt, um nichtlineare
Optimierungsprobleme zu lösen. In dieser Arbeit werden zwei Verfahren, das
halbglatte Newton-Verfahren und das SQP-Verfahren, betrachtet und verglichen.

Das SQP-Verfahren gehört zu den bekanntesten Verfahren der nichtlinearen
Optimierung. Es wurde schon seit den 60er Jahren entwickelt und wurde in vielen
Optimierungsproblemen als Standardwerkzeug angewendet sowie weiterentwickelt.
Das halbglatte Newton-Verfahren ist weniger bekannt als das SQP-Verfahren. Es basiert aber auf
das bekannte Newton-Verfahren.

Bevor wir die beiden Verfahren näher betrachten, werden wir erst mal in
diesem Kapitel die grundlegen Definitionen sowie die wichtigen Ergebnisse
betrachten.

\section{Allgemeine Optimierungsprobleme}

\begin{definition}
Allgemein ist die Aufgabenstellung der Optimierung wie folgt
definiert:
\begin{equation}
  \min_{x \in \F} f(x) \label{eq:op} %use \tag{P} to make (P) as reference
\end{equation}
Die Funktion $f:D \subseteq \R^n \rightarrow \R$ ist die sogennante
Zielfunktion.
$D$ sei der Definitionsbereich von $f$.
$\F$ sei eine nichtleere Teilmenge von $D$, die man als Lösungsmenge bezeichnet.
Alle Elemente von $\F$ werden als zulässige Punkte bezeichnet.
$\F$ wird durch die sogennanten Nebenbedingungen definiert.
\end{definition}

Ein einfaches Beispiel ist das Problem
\[
  \min_{x \in \R}\ (x-1)^2.
\]

Falls $\F = D$ gilt,
dann bezeichnet man das Optimierungsproblem als unrestringiert.
Es besitzt also keine Nebenbedingungen.
Ansonsten heißt es ein restingiertes Optimierungsproblem.

Es ist üblich, dass man nur Minimierungsproblem betrachtet, weil ein
Maximierungsproblem $\max g(x)$ zu dem Minimierungsproblem $\min f(x) := -g(x)$
äquivalent ist.

\begin{definition}
\emph{(Globale und lokale Lösung)}\\
Ein Punkt $\xopt \in \F$ heißt globale Lösung des Problems~\eqref{eq:op} oder
globales Minimum von $f$, wenn
\begin{equation}
  f(\xopt) \leq f(x) \qquad \forall x \in \F
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt strikte globale Lösung des Problems~\eqref{eq:op} oder
striktes globales Minimum von $f$, wenn
\begin{equation}
  f(\xopt) < f(x) \qquad \forall x \in \F\backslash\{\xopt\}
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt lokale Lösung des Problems~\eqref{eq:op} oder
lokales Minimum von~$f$, wenn für eine Umgebung $U(\xopt)$ von $\xopt$
\begin{equation}
  f(\xopt) \leq f(x) \qquad \forall x \in U(\xopt) \cap \F
\end{equation}
gilt.
Ein Punkt $\xopt \in \F$ heißt strikte lokale Lösung des Problems~\eqref{eq:op}
oder striktes lokales Minimum von~$f$, wenn für eine Umgebung $U(\xopt)$ von
$\xopt$
\begin{equation}
  f(\xopt) < f(x) \qquad \forall x \in U(\xopt) \cap \F\backslash\{\xopt\}
\end{equation}
gilt.
Eine Umgebung $U(\xopt)$ von $\xopt$ ist einfach eine offene Menge, die $\xopt$
beinhaltet.
\end{definition}

Wegen dieser Definitionen kommt die Unterscheidung zwischen der globalen
und der lokalen Optimierung. Globale Optimierung versucht, globale Lösungen
zu finden. Lokale Optimierung versucht dagegen, lokale Lösungen zu finden.
Viele Verfahren finden lokale Lösungen, die jedoch nicht unbedingt
globale Lösungen sind. Globale Lösungen sind nicht so einfach zu finden.

\begin{definition}
Das allgemeine nichtlineare Optimierungsproblem ist wie folgt definiert:
\begin{align}
       \min\ & f(x) \\
         \nb & g(x) \leq 0 \\
             & h(x) = 0
\end{align}
Die Zielfunktion ist wieder die Funktion $f:D_f \subseteq \R^n \rightarrow \R$.
Die Nebenbedingungen sind von den Funktionen
$g:D_g \subseteq \R^n \rightarrow \R^p$ und
$h:D_h \subseteq \R^n \rightarrow \R^m$
abhängig.
\end{definition}

D.h. die Menge $\F$ sieht hier so aus:
\begin{equation}
  \F := \{ x | g(x) \leq 0, h(x) = 0  \}.
\end{equation}

Man kann hierbei den Unterschied zwischen der linearen Optimierung und
der nichtlinearen Optimierung gut erkennen.
Bei der linearen Optimierung muss die Zielfunktion linear sein
(d.h. die Zielfunktion besitzt die Form $f(x) = c^T x$, $c \in \R^n$)
und die Nebenbedingungen sind durch lineare Gleichungssysteme oder
Ungleichungssyteme definiert.
Bei der nichtlinearen Optimierung gibt es dagegen keine Einschränkung,
wie die Zielfunktion und die Nebenbedingungen aussehen sollen.

\section{Unrestringierte Optimierungsprobleme}

Wir betrachten nun das unrestringierte Optimierungsproblem
\begin{equation}
  \min_{x \in \R^n} f(x). \label{eq:uop}
\end{equation}

Wir nehmen hier der Einfachheit halber an, dass der Definitionsbereich $D$
gleich $\R^n$ sei.

\begin{theorem}
\emph{(Notwendige Bedingung erster Ordnung)}\\
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und $f$ einmal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt
\begin{equation}
  \nabla f(\xopt) = 0 \label{eq:grad_zero}
\end{equation}
\end{theorem}

Diese Bedingung gilt aber nicht nur für lokales Minimum sondern auch für lokales
Maximum von $f$.

\begin{definition}
\emph{(Stationärer Punkt)}\\
$f$ sei in $\xopt$ differenzierbar. $\xopt$ heißt ein stationärer Punkt von $f$,
wenn $\xopt$ die notwendige Bedingung~(\ref{eq:grad_zero}) erfüllt.
\end{definition}

Viele Optimierungsverfahren suchen in der Regel nach einem stationärem Punkt
von~$f$.
Aber ein stationärer Punkt muss nicht ein globales oder lokales Minimum sein.

\begin{theorem}
\emph{(Notwendige Bedingung zweiter Ordnung)}\\
Seien $\xopt$ eine lokale Lösung des Problems~(\ref{eq:uop}) und $f$ zweimal stetig
differenzierbar in einer Umgebung von $\xopt$, dann gilt~(\ref{eq:grad_zero}) und
\begin{equation}
  x^T f''(\xopt) x \geq 0 \qquad \forall x \in \R^n,
\end{equation}
$f''(\xopt)$ ist also positiv semidefinit.
\end{theorem}

Durch diese notwendige Bedingung können wir zwischen einem lokalen Minimum und
Maximum unterscheiden.

\begin{theorem}
\emph{(Hinreichende Bedingung zweiter Ordnung)}\\
Sei $f$ zweimal stetig differenzierbar in einer Umgebung von $\xopt$.
Die notwendige Bedingung~(\ref{eq:grad_zero}) sei erfüllt und $f''(\xopt)$
sei positiv definit, d.h.
\begin{equation}
  x^T f''(\xopt) x > 0 \qquad \forall x \in \R^n.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des Problems~(\ref{eq:uop}).
\end{theorem}

Diese hinreichende Bedingung benutzt man in der Regel erst dann, wenn man einen
stationären Punkt findet.

\begin{definition}
\emph{(Abstiegsrichtung)}\\
Sei $f:\R^n \rightarrow \R$ differenzierbar in $x$. Ein Vektor
$d \in \R^n\backslash\{0\}$ heißt Abstiegsrichtung von~$f$ in~$x$, wenn
\begin{equation}
  \nabla f(x)^T d < 0
\end{equation}
gilt.
\end{definition}

Ist $\nabla f(x) \neq 0$, dann ist beispielsweise $d = - \nabla f(x)$ eine
Abstiegsrichtung von $f$ in $x$.

\begin{theorem}
Seien $f:\R^n \rightarrow \R$ differenzierbar in $x$ und $d$ eine
Abstiegsrichtung von $f$ in $x$. Dann gibt es ein $\hat{\sigma} > 0$ mit
\begin{equation}
  f( x + \sigma d) < f(x) \qquad \forall \sigma \in ]0, \hat{\sigma}[.
\end{equation}
\end{theorem}

Die meisten Optimierungsverfahren sind iterativ. Sie fangen mit einem
Anfangspunkt $x^0$ an und versuchen dann weitere Punkte ($x^1, x^2, \ldots , x^k
, \ldots$) zu finden, die besser als die vorherige sind.
Viele iterative Verfahren zur Bestimmung eine lokale Lösung sind häufig
Abstiegsverfahren. In der $k$-ten Iteration bestimmen sie zu einem Punkt $x^k$
eine Abstiegsrichtung $d^k$ und eine Schrittweite $\sigma_k$, sodass für
$x^{k+1} := x^k + \sigma_k d^k$
\begin{equation}
  f(x^{k+1}) < f(x^k)
\end{equation}
gilt.

Das Gradientenverfahren ist ein einfaches Abstiegsverfahren,
welches die negative Gradienten als Abstiegsrichtungen verwendet.

\begin{algorithm}
\emph{(Gradientenverfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_GV}
        $\Rightarrow$ STOP.
  \item Setze $d^k := - \nabla f(x^k)$.
  \item Bestimme $\sigma_k$ so, dass
        \begin{equation}
          f(x^k + \sigma_k d^k) < f(x^k + \sigma d^k)
            \qquad \forall \sigma \geq 0.
        \end{equation}
  \item Setze $x^{k+1} := x^k + \sigma_k d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_GV}.
\end{enumerate}
\end{algorithm}

Eine andere Möglichkeit ist, dass man das Newton-Verfahren verwendet,
um die Lösung der Gleichung~\eqref{eq:grad_zero} zu finden.

\begin{algorithm}
\emph{(Newton-Verfahren)}
\begin{enumerate}
  \item Wähle einen Startpunkt $x^0$ und ein Abbruchkriterium $\epsilon > 0$.
        Setze $k := 0$.
  \item Ist $||\nabla f(x^k)|| < \epsilon$ \label{list:stop_criteria_NV}
        $\Rightarrow$ STOP.
  \item Berechne die Lösung $d$ des linearen Gleichungssystems
        \begin{equation}
          f''(x^k) d = - \nabla f(x^k).
        \end{equation}
        Setze $d^k := d$.
  \item Setze $x^{k+1} := x^k + d^k$ und $k := k+1$ $\Rightarrow$
        Gehe zu Schritt~\ref{list:stop_criteria_NV}.
\end{enumerate}
\end{algorithm}

Man kann auch noch eine Scrittweitensteuerung durchführen, dann bekommt man ein
Abstiegsverfahren, welches man als das gedämpfte Newton-Verfahren bezeichnet.
Man ersetzt dazu den Schritt 4 in dem Newton-Verfahren mit den Schritten 4 und 5
in dem Gradientenverfahren.

\section{Restringierte Optimierungsprobleme}

\begin{definition}
\emph{Optimierungsproblem mit linearen Gleichungsnebenbedingungen}\\
\begin{align}
  \min_{x \in \R^n}\ & f(x) \label{eq:opmlgnb} \\
              \nb & Ax = b \notag
\end{align}
$A$ sei eine $(m \times n)$-Matrix und $b$ sei ein Vektor mit $m$ Elementen.
\end{definition}

D.h. die Menge $\F$ sieht hier so aus:
\begin{equation}
  \F := \{ x | A x = b  \}.
\end{equation}

\begin{theorem}
\emph{Notwendige Bedingung erster Ordnung}\\
Sei $\xopt$ lokale Lösung des linearen restringierten Optimierungsproblems und
$f$ sein in $\xopt$ differenzierbar. Dann gibt es ein $\lambda \in \R^m$ mit
\begin{equation}
  \nabla f(\xopt) + A^T \lambda = 0.
\end{equation}
Hat A einen vollen Rang, dann ist $\lambda$ eindeutig zu bestimmen.
\end{theorem}

Diese Bedingung heißt die Multiplikatoren Regel von Lagrange. Man bezeichnet
$\lambda$ als die Lagrange-Multiplikator.

\begin{theorem}
\emph{Hinreichende Bedingung zweiter Ordnung}\\
Sei $f$ in $\xopt$ zweimal stetig differenzierbar. Die notwendige Bedingung
erster Ordnung sei erfüllt. Es gäbe eine Konstante $\alpha > 0$ mit
\begin{equation}
  d^T f''(x) d \geq \alpha ||d||^2 \qquad d \in \kr A.
\end{equation}
Dann ist $\xopt$ eine strikte Lösung des linearen restringierten Problems.
\end{theorem}

\begin{definition}
\emph{Nullraum-Matrix}\\
Eine $(n \times l)$-Matrix $Z$ heißt Nullraum-Matrix von $A$, wenn für $d \in
\R^n$ gilt
\begin{equation}
d \in \kr A \quad \Leftrightarrow \quad d = Z z \text{ für ein } z \in \R^l.
\end{equation}
D.h., $\im Z = \kr A$.
\end{definition}

Sei $w$ eine Lösung von der Gleichung $Ax=b$. Man kann nun für $\F$ so
schreiben:
\begin{equation}
  \F = w + \kr A = w + \im Z = w + \{ Z z | z \in \R^l \}.
\end{equation}

Das Problem~\eqref{eq:opmlgnb} ist dann äquivalent zu
\begin{equation}
  \min_{z \in \R^l} F(z) := f(w + Zz).
\end{equation}

% TODO: Approximation der Gradient und Hesse-Matrix?
